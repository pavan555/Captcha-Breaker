{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Captcha Breaker\n",
    "I have done a project on deep learning called simple captcha breaker based on deep learning\n",
    "for opencv written by Adrian Rosebrock.\n",
    " \n",
    " I am going to explain how i did this project.Here i created my own custom dataset by extracting each digits in the picture.\n",
    " \n",
    " \n",
    " ![example](https://github.com/pavan555/Captcha-Breaker/blob/master/downloads/00446.jpg?raw=true) ==> 1738\n",
    "\n",
    " \n",
    " There are mainly 4 parts in this Project.\n",
    " \n",
    " \n",
    " 1. Downloading a set of captcha images\n",
    " 2. Labeling and annotating images for our training\n",
    " 3. Training a CNN on our custom dataset\n",
    " 4. Evaluating and Testing our trained Convolutional Neural Network    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 1. Downloading a set of captcha images\n",
    "first of all, select a website that will provide captchas like the below images. I have downloaded the images from [Simple CAPTCHA](https://www.e-zpassny.com/vector/jcaptcha.do) (note: which is not working right now)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "   ![ex images](https://user-images.githubusercontent.com/25476729/63042877-a1ef1080-bee8-11e9-984f-6b4b5d5f4c23.png)\n",
    "\n",
    "  Figure : **Example Images**\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The sample code for downloading the images is displayed below.\n",
    "\n",
    "```python\n",
    "r= requests.get(\"https://www.e-zpassny.com/vector/jcaptcha.do\")\n",
    "path=os.path.sep.join([args[\"output\"],\"{}.jpg\".format(str(total).zfill(5))])\n",
    "file = open(path,\"w\")\n",
    "file.write(r.content)\n",
    "file.close()\n",
    "```\n",
    "I downloaded approximately 500 images and saved in downloads path.\n",
    "\n",
    "However, these are just raw captcha images.\n",
    "We need to extract and label each of the digits in the captchas to create our training data set.\n",
    "This will be accomplished by next section.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "##  2. Labeling and annotating images for our training\n",
    "\n",
    "To extract each digit and label our digit, i used [label_the_data.py](https://github.com/pavan555/Captcha-Breaker/blob/63851759c537364f52c958dc643f30f72b2e66a1/label_the_data.py) file.\n",
    "\n",
    "OpenCV is a popular framework for computer vision and image processing. I utilized OpenCV for processing the captcha images.\n",
    "\n",
    "The basic idea is to split the CAPTCHA image into four identical parts( because we know that there will be only 4 digits in the image) and label the data.\n",
    "The main problem here is splitting \n",
    "\n",
    "(i) we can't do it manually 'cause it would take months to split and label each image\n",
    "\n",
    "(ii)we can't just split the image into four equal-sized chunks because the CAPTCHA randomly places the digits in different horizontal positions.\n",
    "like below\n",
    "\n",
    "![gif](https://user-images.githubusercontent.com/25476729/63044371-b08af700-beeb-11e9-858b-89738961326a.gif)\n",
    "\n",
    "Luckily,We can automate these using OpenCV...\n",
    "\n",
    "(i)So we will start with raw CAPTCHA image\n",
    "\n",
    "![captcha](https://user-images.githubusercontent.com/25476729/63083566-a8bc6880-bf66-11e9-82cc-9609c2fd8929.png)\n",
    "\n",
    "\n",
    "(ii) Use padding beacuse if the images in captcha attached to borders then there is a chance to loose the number in the image so we are using padding across the border.\n",
    "\n",
    "[lines]:https://github.com/pavan555/Captcha-Breaker/blob/63851759c537364f52c958dc643f30f72b2e66a1/label_the_data.py#L19-L30\n",
    "\n",
    "\n",
    "(iii) Then we will convert our image into pure white and black (this is called thresholding)\n",
    "so that it will be easier to find continuous regions.\n",
    "![Threshold](https://user-images.githubusercontent.com/25476729/63087231-3dc35f80-bf6f-11e9-9409-35ab8cd5ba97.png)\n",
    "\n",
    "(iv) we will use OpenCV's _**findContours()**_  function to detect the digits that contain continuous blobs of pixels together.\n",
    "![digits](https://user-images.githubusercontent.com/25476729/63091055-cdbad680-bf7a-11e9-8086-258abd3f6297.png)\n",
    "\n",
    "(v) Then each rectangle( Region of interest )  will be displayed to classify with hand and we can save the images in the corresponding classified directory according to the entered key by us.\n",
    "Those ROI images will be given like below.\n",
    "![roi1](https://user-images.githubusercontent.com/25476729/63092132-4d967000-bf7e-11e9-9224-c2d8192f75bc.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now that we have a way to extract individual digits,run it across all CAPTCHA images we have.The Goal is to collect\n",
    "different variations of a each digit.we can save each digit in it's own folder to keep things organized.\n",
    "\n",
    "Here's picture of my 6 digit dataset after i extracted all of my captcha images.\n",
    "\n",
    "![6-digit dataset](https://user-images.githubusercontent.com/25476729/63092946-08c00880-bf81-11e9-82ed-d0c9e22c0bc2.png)\n",
    "\n",
    "Figure : *Some of the 6 digits extracted from 2000+ images. I ended up with 254 different \"6\" images*\n",
    "\n",
    "\n",
    "### The sample code for annotating the images is displayed below.\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "thresh=cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)[1]\n",
    "blobs=cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "blobs = blobs[1] if imutils.is_cv2 else blobs[0]\n",
    "blobs=sorted(blobs,key=cv2.contourArea,reverse=True)[:4]\n",
    "for b in blobs:\n",
    "    try:\n",
    "        (x,y,w,h)=cv2.boundingRect(b)\n",
    "        #region of interest will be\n",
    "        roi = gray[y-5 : y+h+5, x-5 : x+w+5]\n",
    "\n",
    "        cv2.imshow(\"roi\",imutils.resize(roi,width=28))\n",
    "        #careful when clicking the key beacuse it will be the class for the image\n",
    "        key=cv2.waitKey(0)\n",
    "        #if key clicked is ` then escape that image\n",
    "        if(key==ord(\"`\")):\n",
    "            print(\"\\033[93m [INFO...] ignoring the image \\033[00m\")\n",
    "            continue\n",
    "\n",
    "        key=chr(key).upper()\n",
    "        dirPath = os.path.sep.join([args[\"output\"],key])\n",
    "        if not os.path.exists(dirPath):\n",
    "            os.makedirs(dirPath)\n",
    "\n",
    "        count = counts.get(key,1)\n",
    "        #Str().zfill() Returns a copy of the string with '0' characters padded to the leftside of the given string.\n",
    "        #ex zfill(3) ==> 000name\n",
    "        p=os.path.sep.join([dirPath,\"{}.png\".format(str(count).zfill(6))])\n",
    "        cv2.imwrite(p,roi)\n",
    "```"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Training a CNN on our custom dataset\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python2",
   "language": "python",
   "display_name": "Python 2"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}